/*
  created
  Martin Rupp <martin.rupp@gcsc.uni-frankfurt.de>
  Sebastian Reiter <s.b.reiter@googlemail.com>
  y11 m04 d13

  refactored
  Torbj√∂rn Klatt <torbjoern@torbjoern-klatt.de>
  y12 m03 d29
*/

/** \page pageUG4Profiling Profiling UG4

- \ref secEnableProfiling "Enable Profiling in UG4"
- \ref secProfilingLUA "Profiling your LUA Script"
- \ref secProfilingRegistry "Profiling Registry"
- \ref secProfilingYourCode "Profiling your C/C++ code"
- \ref secViewProfilingNodes "View profiling statistics"

For any questions, contact martin.rupp@gcsc.uni-frankfurt.de or 
sebastian.reiter@gcsc.uni-frankfurt.de .


<hr>
\section secEnableProfiling Enable Profiling in UG4

You enable profiling in UG4 by setting the CMake flag <tt>-DPROFILER=ON</tt>.
So if have a shell open in your subdirectory <tt>build_debug</tt> (as 
explained \ref pageInstallUG4 "here" or 
\ref secInstallEcpliseUseMakefiles "here"), you enter
\code
cmake -DPROFILER=ON ..
make
\endcode
Note that <em>CMake</em> "remembers" the flags you set.
You can see the flags set in the output (for not changing any flags just enter 
<tt>cmake ..</tt>). 
To enable profiling of the PCL (Parallel Communication Layer), set 
<tt>-DPROFILE_PCL=ON</tt>.
Check the output of <tt>cmake ..</tt> for changes and additional flags.
Keep in mind that you have to do a make when changing <em>Cmake</em> flags.


<hr>
\section secProfilingLUA Profiling your LUA Script

To enable profiling of your LUA Script, simply add a <tt>ProfileLUA(true)</tt> 
at the beginning of your script.
For the moment, we only profile the top-level calls, not all subroutine calls. 
This has performance reasons.
Expect a performance drawback when calling small functions very often.
You can also disable the LUA compiler for these calls:
\verbatim
ProfileLUA(false)
AssembleLinearOperatorRhsAndSolution(linOp, u, b)
ProfileLUA(true)
\endverbatim


<hr>
\section secProfilingRegistry Profiling Registry

You can enable profiling all calls made through the <strong>UG4</strong> 
<em>Registry / Brige</em> by calling <em>CMake</em> with
\verbatim
cmake -DPROFILE_BRIDGE=ON ..
\endverbatim


<hr>
\section secProfilingYourCode Profiling your C/C++ code

If you want measure the time spend in your functions or in sections of your 
code, you can use our profiling functions:
\code
#include  "common/profiler/profiler.h"
\endcode
<ul>
  <li><tt>PROFILE_BEGIN(name)</tt> is for profiling sections of code.
    Profiling is done from the line where <tt>PROFILE_BEGIN(name)</tt> is until 
    <tt>PROFILE_END()</tt> or until the end of the scope where 
    <tt>PROFILE_BEGIN(name)</tt> was in.
    \verbatim
    void MyFunction(size_t n)
    {
      // first do some stuff
      
      PROFILE_BEGIN(CalculationA)
      
      // do calculation A
      
      PROFILE_END()
      
      PROFILE_BEGIN(CalculationB)
      
      // do calculation B
      
      PROFILE_END()
      
      PROFILE_BEGIN(CalculationRest)
      // do rest stuff 
      // CalculationRest is evaluated until the end
    }
    \endverbatim

    Here the profile node <tt>Calculation A</tt> measures only the part in 
    <tt>do calculation A</tt>, <tt>Calculation B</tt> measures only the part in 
    <tt>do calculation B</tt>, and <tt>CalculationRest</tt> measures only the 
    part in <tt>do rest stuff</tt>. 
  </li>
  <li><tt>PROFILE_FUNC()</tt> is for profiling functions:
    Put <tt>PROFILE_FUNC()</tt> at the beginning of the function.
    Note that <tt>PROFILE_FUNC()</tt> is basically only a <tt>PROFILE_BEGIN</tt>
    with the function name. Example:
    \verbatim
      void MyFunction(size_t n)
      {
        PROFILE_FUNC(); // Same as PROFILE_BEGIN(MyFunction)
        
        // do stuff 
      }
    \endverbatim
    \note When you put <tt>PROFILE_FUNC()</tt> not at the beginning of the 
    scope you or others might get unexpected behaviour.
  </li>
  <li>When a profile node is auto-ended by the scope mechanism, we use 
    destructors to accomplish this.
    However, it is possible that some destructors are called AFTER the 
    destructor of the profile node.
    The reason for this is that destructors are called in reverse order of 
    constructors:
    First constructed, last destructed (see 
    <a href="http://www.parashift.com/c++-faq-lite/dtors.html#faq-11.2">here</a>). 
    So the times spend in some destructors might not be added to this profile 
    node.
    Examples for this are objects which are declared before 
    <tt>PROFILE_BEGIN</tt> or arguments with destructors which are passed as 
    value:
    \verbatim
    void MyFunction(std::vector<int> vec)
    {
      PROFILE_FUNC() // does not measure destructor of vec.
      
      std::vector<int> vec2;
      
      PROFILE_BEGIN(MyFunctionSectionA)  // does not measure destructor of vec and vec2.
      
      std::vector<int> vec3;
      
      // implicit destructor of vec3
      // implicit PROFILE_END(MyFunctionSectionA)
      // implicit destructor of vec2
      // implicit PROFILE_END(MyFunction)
      // implicit destructor of vec
    }
    \endverbatim
  </li>
  <li>You can also nest Profiling:
    \verbatim
      void MyFunction(size_t n)
      {
        PROFILE_FUNC()
        
        for(size_t i=0; i<5; i++)
        {
          PROFILE_BEGIN(MyFunction_InLoop);
          // do some stuff
        }		
        
        // do some other stuff (not measure by MyFunction_InLoop anymore)
      }
    \endverbatim
  </li>
  <li>Internally we use the 
    <a href="http://sourceforge.net/projects/shinyprofiler/">Shiny Profiler</a> 
    for profiling.
    <em>Shiny</em> is fast, but not priceless. 
    Be aware that <tt>PROFILE_BEGIN</tt> has a small overhead, so dont use it 
    in functions which do only very little.
  </li>
</ul>


<hr>
\section secViewProfilingNodes View profiling statistics

<ul>
  <li>
    \verbatim
    SetOutputProfileStats(true)
    \endverbatim
    With this, profiler statistics are output at the end of the execution of 
    <tt>ugshell</tt>, there you will see the total call tree (from main on) 
    and a flat list with timings.
  </li>
  <li>This can be pretty much information, and that is why there is also a 
    direct way of accessing timing information for a specific Profiler Node 
    (Profiler Nodes are all nodes which got created with <tt>PROFILE_BEGIN</tt>
    or <tt>PROFILE_FUNC</tt>.
    Note that if that part of code never got executed, the profiler nodes in 
    there do not exist).
  </li>
</ul>

<ul>
  <li>You can access the profiling nodes directly from the script with
    \verbatim
    UGProfileNode *GetProfileNode(const char *str);
    \endverbatim
    With <tt>GetProfilerAvailable() == true</tt> you can check if a profiler 
    is available.

    The <tt>UGProfilerNode</tt> has the following functions:
    \verbatim
    class UGProfilerNode
    {
      double get_avg_entry_count() const;                         // number of entries in this profiler node
      double get_avg_self_time_ms() const;                        // time in milliseconds spend in this node excluding subnodes
      double get_avg_total_time_ms() const;                       // time in milliseconds spend in this node including subnodes
      string call_tree(double dMarginal=0.0) const;               // returns string with call tree
      string child_self_time_sorted(double dMarginal=0.0) const;  // string with sorted childs (sorted by self time)
      string total_time_sorted(double dMarginal=0.0) const;       // string with sorted childs (sorted by total time)
      string entry_count_sorted(double dMarginal=0.0) const;      // string with sorted childs (sorted by entry count)
      bool is_valid() const;                                      // true if this is a valid node (i.e. != NULL)
    }
    \endverbatim
  </li>
  <li>IMPORTANT:
    If <tt>dMarginal != 0.0</tt>, only nodes which account for more than 
    <tt>dMarginal*100 % of the total time</tt> are part of the output.
    So if you want to print the call tree, and want to display only nodes which 
    account for more than 3% of the total time, you can write
    \verbatim
    GetProfileNode("main"):call_tree(0.03)
    \endverbatim
  </li>
  <li>Example Code to be profiled:
    \verbatim
    void FunctionA(double &b)
    {
      PROFILE_FUNC();
      for(size_t i=0; i<1000; i++)
        b += sin(b);
    }

    void FunctionA_bad(double &b)
    {
      PROFILE_FUNC();
      for(size_t i=0; i<1000; i++)
      {
        // this section is too small!
        PROFILE_BEGIN(FuncationA_bad_in_loop)
        b += sin(b);
      }
    }

    void FunctionB(double &b)
    {
      PROFILE_FUNC();
      for(size_t i=0; i<1000; i++)
      {
        FunctionA(b);
        FunctionA_bad(b);
      }
    }

    void FunctionC(double &b)
    {
      PROFILE_FUNC();
      FunctionB(b);
      FunctionA(b);
      FunctionB(b);
    }

    void MyFunction()
    {
      PROFILE_FUNC();
      double d=0.1;
      FunctionC(d);
      cout << d << endl;
    }
    \endverbatim
  </li>
  <li>Now we write a LUA Script:
    \verbatim
    MyFunction()
    -- check if profiler is available
    if GetProfilerAvailable() == true then
      -- get node
      pn = GetProfileNode("MyFunction")
      -- check if node is valid
      if pn:is_valid() then
        print("Called MyFunction "..pn:get_avg_entry_count().." times.")
        print("Spend "..pn:get_avg_self_time_ms().." ms for MyFunction alone (without child nodes).")
        print("Spend "..pn:get_avg_total_time_ms().." ms in MyFunction altogether.\n")
        
        print("MyFunction call tree")
        print(pn:call_tree())
        print("MyFunction call list self time sorted")
        print(pn:child_self_time_sorted())
        print("MyFunction call list total time sorted")
        print(pn:total_time_sorted())
        print("MyFunction call list entry count sorted")
        print(pn:entry_count_sorted())
      else
        print("MyFunction is not known to the profiler.")
      end
    else
      print("Profiler not available.")
    end	
    \endverbatim
  </li>
  <li>Results:
    \verbatim
    Called MyFunction 1 times.
    Spend 0.1044 ms for MyFunction alone (without child nodes).
    Spend 725.6421 ms in MyFunction altogether.

    MyFunction call tree
    call tree                                            hits       self time      total time 
    MyFunction                                             1  104.4 us    0% 725.64 ms  100% 
    FunctionC                                             1    900 ns    0% 725.54 ms   99% 
      FunctionB                                            2  579.6 us    0% 725.49 ms   99% 
      FunctionA                                        2000 98.969 ms   13% 98.969 ms   13% 
      FunctionA_bad                                    2000 243.79 ms   33% 625.94 ms   86% 
        FuncationA_bad_in_loop                         2e+06 382.15 ms   52% 382.15 ms   52% 
      FunctionA                                            1   49.5 us    0%   49.5 us    0% 

    MyFunction call list self time sorted
    self time sorted                                     hits       self time      total time 
    FunctionC                                              1    900 ns    0% 725.54 ms   99% 
    FunctionA                                              1   49.5 us    0%   49.5 us    0% 
    MyFunction                                             1  104.4 us    0% 725.64 ms  100% 
    FunctionB                                              2  579.6 us    0% 725.49 ms   99% 
    FunctionA                                           2000 98.969 ms   13% 98.969 ms   13% 
    FunctionA_bad                                       2000 243.79 ms   33% 625.94 ms   86% 
    FuncationA_bad_in_loop                             2e+06 382.15 ms   52% 382.15 ms   52% 

    MyFunction call list total time sorted
    total time sorted                                    hits       self time      total time 
    FunctionA                                              1   49.5 us    0%   49.5 us    0% 
    FunctionA                                           2000 98.969 ms   13% 98.969 ms   13% 
    FuncationA_bad_in_loop                             2e+06 382.15 ms   52% 382.15 ms   52% 
    FunctionA_bad                                       2000 243.79 ms   33% 625.94 ms   86% 
    FunctionB                                              2  579.6 us    0% 725.49 ms   99% 
    FunctionC                                              1    900 ns    0% 725.54 ms   99% 
    MyFunction                                             1  104.4 us    0% 725.64 ms  100% 

    MyFunction call list entry count sorted
    entry count sorted                                   hits       self time      total time 
    MyFunction                                             1  104.4 us    0% 725.64 ms  100% 
    FunctionC                                              1    900 ns    0% 725.54 ms   99% 
    FunctionA                                              1   49.5 us    0%   49.5 us    0% 
    FunctionB                                              2  579.6 us    0% 725.49 ms   99% 
    FunctionA                                           2000 98.969 ms   13% 98.969 ms   13% 
    FunctionA_bad                                       2000 243.79 ms   33% 625.94 ms   86% 
    FuncationA_bad_in_loop                             2e+06 382.15 ms   52% 382.15 ms   52% 
    \endverbatim
    Here we see that <tt>FunctionA_bad</tt> takes six times as long as 
    <tt>FunctionA</tt>, even though they both perform the same task.
    This is because the small overhead of <tt>PROFILE_BEGIN</tt> accumulated 
    to a measureable time when it was executed two million times.
  </li>
  <li><strong>Explanations</strong>:
    <ul>
      <li>The <tt>self time</tt> of a method is the time spent in this method, 
        without the time spent in all methods called from the first one &mdash; 
        if they also use the profiler.
        To make it clear:
        If a called method doesn't use the profiler the time spent for it 
        accounts for the <tt>self time</tt> of the calling method!
      </li>
    </ul>
  </li>
  <li>Utilities for the <strong>Analysis of Profiling Aesults</strong> 
    (automatic comparison of several simulation runs etc.) see 
    \ref pageUG4ScalabilityTests .
  </li>
</ul>

*/
